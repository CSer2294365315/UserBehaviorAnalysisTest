Redis，JVM，Leetcode，MySQL，放在后面，中小公司问
Linux命令   常用的记住，直说高级的，至少5个，低级的不要说
Shell    awk，sed，sort，cut 最近一年问的少，记住这几个名称就可以，用来切分字符串的
        问法：写没写过shell脚本。群起脚本（Apache才写过），建表导数据（mySQL），分发，数仓每一层的导入导出
		 写脚本步骤：ADS到DWD：5步骤：bin/bash, 数据库名称App=GAMLL，获取当前时间date，正常业务逻辑，替换数据库和日志，执行对应的脚本
就要这种难度就OK的意思是？面试就说到这种粒度？
Hadoop 入门：两道面试题，常用的端口号，安装集群过程的8个配置文件怎么配置
			常用端口号：50070 查看HDFS运行情况,8088任务运行情况，19888历史服务器，必须会。
			怎么监控HDFS运行情况。整个大数据集群有没有组监控。Hadoop，自带的，监控HDFS，8088，监控每个job运行情况，19888任务运行情况
			各种框架的监控，Kafka，Spark等，说出名字来
			配置文件：common，hdfs，yarn，mr
			common：core-site:
			hdfs-site
			yarn-site
			mared-site
			hadoop-env，yarn-env，mapred-env，mapred-env，slaves。
			配置slaves，无空格，无空行
			hadoop1和hadoop2的区别：加了yarn，解耦
HDFS	读写流程，
         要建立小群，老师也ok、需要建群，把老师加进去，组里要有大牛，要有老师。
		 笔试题，都是拍照，在群里面解决的。
		 10亿的数据，复制粘贴到百度，都有答案。都是小黑屋，没人管你。公司要干活的，1小时工资黑高
		 越是高不可攀的题，越要百度，不要自己想
		 助攻神器：文字识别。何老师要，天若OCR识别
		 不要想现场通过实力去解决，笔试题比较偏

		会问，这个人是不是学弟学妹，所以，要给老师备注好名字

		侃快，给人一种无所畏惧的感觉

mapreduce，map之后，reduce之前，数据首先进入到getPartition方法，进入环形缓冲区，不准确
默认100M，到达80%的时候，反向溢写，排序，对Key的索引排。字典序排，快排，
产生大量溢写文件，进行归并排序。存储在对应的磁盘上。
如果这样回答，只有50分，后50分：把shuffle的优化措施加上，
就能得到满分。要顺着线程说
100M，开发的时候调大，200M。反向溢写，跳到95%。为什么就优化了呢？
优化的原理：减少了一些的个数。归并排徐过程中，增加combine
不影响最终的业务逻辑。求平均值的时候，不能用业务逻辑。
说怎么优化，说优化的原理。
压缩，优化的原理：然后相关性拓展。
输入端，切片，拓展到，那种支持切片。lzo，bzip2
mapreduce端，snappy和lzo
reduce端输出端。要拓展着说，自己拓展，有线索的拓展，节奏就顺着他走了
说现象，拓展设计原因，拓展优化，以及优化的原因。可以加这些内容的。单个maptask默认内存多大，
maptask内存，reducetask内存。1个G
单节点内存
单任务内存
基本过程，中间糅合着优化，以及原理。是必须的，否则面试官问什么你只回答什么，会认为你不合格
以前写的可以用。可能要做一些联合
调优，可能证明自己真正干过，没调过，就说明你没干过。干过就必须要调

问老师，自己说流程，分析一些关键地方的设计原因（自己的理解），这么设计的优缺点，又该怎么解决缺点。最后说下来说的就很多。这样行不行？
自己试过，比如Spark调优那些，要说1个多小时。行不行？

调优算是经验，必须说，证明你干过

回答问题，结合生产环境大，比如shuffle内存怎么条，自己怎么用的。说清楚。而不仅仅是理论
调优就是最好的怎么用的

HDFS 小文件问题。小文件打包成har包，优化NameNode
举例说明，算数说明

说原理，也要说具体你怎么用的，怎么调优的，这就能证明你用过。那可以多说

自己能够自行拓展，拓展起来就说个不停，说到这个知识点，会联想起相关知识点。光自己说，是不是不太好。我自己试过
小文件，JVM重用，效率提高了60%

问大海哥

多说一点，自己是怎么用的，怎么优化的，后者优化相关的。就好使。切记

不拓展，不行，

自己扩展的度，怎么掌握？

整个集群内存大小，大公司，40~50T所有

Yarn工作机制


大海哥，想问个问题，

Apache，默认是容量调度器，CDH，公平调度器
FIFO调度器：

性能差集群，用容量，中小型公司。
公平调度去，并发度高。内存，磁盘，网络IO充足才行。大公司用

面试官会继续问。默认有几个队列，默认就一个default队列。设置多个队列。
小白，所有资源在一起。如果一个任务失败，那所有任务都失败。分成几块，只会一块出问题
按部门分，，按照部分分多一点。
或者按框架分，比如Spark队列，Hive队列

调度器：FIFO，容量，公平。FIFO单队列，每个先进先出，并发度是1
容量=多个FIFO。以及容量调度器的调度过程
公平。

队列个数的设置原则：一种是按照业务线，解耦，降低风险。或者按照技术框架分


Zookeeper 常用命令+选举机制+ 那个算法可以提一下，大厂会问

Flume 问问自己，flume能蹦出点啥 Flume监控

source 选的tailDir，为什么用这个，用什么好处：断点续传，多目录
tailDir宕机了，会产生什么问题？ 没问题，重启就好了。不要被面试官问道，你觉得怎么样就说怎么样
1.7之后，出现的tailDir，之前，用的是自定义source
重复数据，去重，tailDir宕机，递归读取文件问题。自己在那里说，巴拉巴拉的

一遍分析问题，一边解决问题，实现推进


由自定义offset，推到如果产生重复 怎么办？去重。redis，groupBy

默认不支持递归遍历文件夹：自定义source，写递归代码，然后用tailDir读
复杂的问题一步一步的拆分，面试的时候就这样

几种channel，各种channel的优缺点。kafka channal，下一阶段必须是kafka
Kafka存磁盘。可靠性高，省去sink，效率高。
kafka有bug。额外的加上了topic前缀，传到flume，还需要额外的去掉

老师也是按照一条线来做的
从source，说到channal，说到sink。
sink，就想到什么问题。比如小文件问题
自拓展。

flume拦截器，不要有太复杂的逻辑，项目，简单的ETL+分类

企业开发，event类型，start类型。

让你介绍Flume，你要把你项目当中怎么用的给说】引进来，这就是经验。需要处理一下。混合

那问题又来了。一张表一个topic，做适当的聚合
如果自定义拦截器。
为了快，日志服务器不落盘。这么做，好处是什么，坏处是什么

把每个学科说多久，总结出来，给老师看看，怎么压缩。

基本就是上课讲的干货。自己能巴拉巴拉的说出来，但是太多了。

ganglia，要补充。原理：put事务，尝试提交次数，如果尝试次数远远大于成功，说明存在大量的充实。
说明flume性能不稳定。那就优化。


5台日日志服务器，+优化，问flume怎么优化
增加台数，增加内存
HDFS sink
file channel，多目录
项目和单纯的技术，要融合一下             。  奇数
说到技术点要带出来，把相关的优化带出来，会出什么问



Redis，JVM，Leetcode，MySQL，放在后面，中小公司问
Linux命令   常用的记住，直说高级的，至少5个，低级的不要说
Shell    awk，sed，sort，cut 最近一年问的少，记住这几个名称就可以，用来切分字符串的

问法：写没写过shell脚本。群起脚本（Apache才写过），建表导数据（mySQL），分发
，数仓每一层的导入导出
		 写脚本步骤：ADS到DWD：5步骤：bin/bash,
数据库名称App=GAMLL，获取当前时间date，正常业务逻辑，替换数据库和日志，执行
对应的脚本
就要这种难度就OK的意思是？面试就说到这种粒度？
Hadoop 入门：两道面试题，常用的端口号，安装集群过程的8个配置文件怎么配置
			常用端口号：50070
查看HDFS运行情况,8088任务运行情况，19888历史服务器，必须会。

怎么监控HDFS运行情况。整个大数据集群有没有组监控。Hadoop，自带的，监控HDF
S，8088，监控每个job运行情况，19888任务运行情况
			各种框架的监控，Kafka，Spark等，说出名字来
			配置文件：common，hdfs，yarn，mr
			common：core-site:
			hdfs-site
			yarn-site
			mared-site
			hadoop-env，yarn-env，mapred-env，mapred-env，slaves。
			配置slaves，无空格，无空行
			hadoop1和hadoop2的区别：加了yarn，解耦
HDFS	读写流程，
         要建立小群，老师也ok、需要建群，把老师加进去，组里要有大牛，要有老师。
		 笔试题，都是拍照，在群里面解决的。

10亿的数据，复制粘贴到百度，都有答案。都是小黑屋，没人管你。公司要干活的，1小
时工资黑高
		 越是高不可攀的题，越要百度，不要自己想
		 助攻神器：文字识别。何老师要，天若OCR识别
		 不要想现场通过实力去解决，笔试题比较偏

		会问，这个人是不是学弟学妹，所以，要给老师备注好名字

		侃快，给人一种无所畏惧的感觉

mapreduce，map之后，reduce之前，数据首先进入到getPartition方法，进入环形缓冲区，不准
确
默认100M，到达80%的时候，反向溢写，排序，对Key的索引排。字典序排，快排，
产生大量溢写文件，进行归并排序。存储在对应的磁盘上。
如果这样回答，只有50分，后50分：把shuffle的优化措施加上，
就能得到满分。要顺着线程说
100M，开发的时候调大，200M。反向溢写，跳到95%。为什么就优化了呢？
优化的原理：减少了一些的个数。归并排徐过程中，增加combine
不影响最终的业务逻辑。求平均值的时候，不能用业务逻辑。
说怎么优化，说优化的原理。
压缩，优化的原理：然后相关性拓展。
输入端，切片，拓展到，那种支持切片。lzo，bzip2
mapreduce端，snappy和lzo
reduce端输出端。要拓展着说，自己拓展，有线索的拓展，节奏就顺着他走了
说现象，拓展设计原因，拓展优化，以及优化的原因。可以加这些内容的。单个maptask默认内存多
大，
maptask内存，reducetask内存。1个G
单节点内存
单任务内存
基本过程，中间糅合着优化，以及原理。是必须的，否则面试官问什么你只回答什么，会认为你不合
格
以前写的可以用。可能要做一些联合
调优，可能证明自己真正干过，没调过，就说明你没干过。干过就必须要调

问老师，自己说流程，分析一些关键地方的设计原因（自己的理解），这么设计的优缺点，又该怎么
解决缺点。最后说下来说的就很多。这样行不行？
自己试过，比如Spark调优那些，要说1个多小时。行不行？

调优算是经验，必须说，证明你干过

回答问题，结合生产环境大，比如shuffle内存怎么条，自己怎么用的。说清楚。而不仅仅是理论
调优就是最好的怎么用的

HDFS 小文件问题。小文件打包成har包，优化NameNode
举例说明，算数说明

说原理，也要说具体你怎么用的，怎么调优的，这就能证明你用过。那可以多说

自己能够自行拓展，拓展起来就说个不停，说到这个知识点，会联想起相关知识点。光自己说，是不
是不太好。我自己试过
小文件，JVM重用，效率提高了60%

问大海哥

多说一点，自己是怎么用的，怎么优化的，后者优化相关的。就好使。切记

不拓展，不行，

自己扩展的度，怎么掌握？

整个集群内存大小，大公司，40~50T所有

Yarn工作机制


大海哥，想问个问题，

Apache，默认是容量调度器，CDH，公平调度器
FIFO调度器：

性能差集群，用容量，中小型公司。
公平调度去，并发度高。内存，磁盘，网络IO充足才行。大公司用

面试官会继续问。默认有几个队列，默认就一个default队列。设置多个队列。
小白，所有资源在一起。如果一个任务失败，那所有任务都失败。分成几块，只会一块出问题
按部门分，，按照部分分多一点。
或者按框架分，比如Spark队列，Hive队列

调度器：FIFO，容量，公平。FIFO单队列，每个先进先出，并发度是1
容量=多个FIFO。以及容量调度器的调度过程
公平。

队列个数的设置原则：一种是按照业务线，解耦，降低风险。或者按照技术框架分


Zookeeper 常用命令+选举机制+ 那个算法可以提一下，大厂会问

Flume 问问自己，flume能蹦出点啥 Flume监控

source 选的tailDir，为什么用这个，用什么好处：断点续传，多目录
tailDir宕机了，会产生什么问题？
没问题，重启就好了。不要被面试官问道，你觉得怎么样就说怎么样
1.7之后，出现的tailDir，之前，用的是自定义source
重复数据，去重，tailDir宕机，递归读取文件问题。自己在那里说，巴拉巴拉的

一遍分析问题，一边解决问题，实现推进


由自定义offset，推到如果产生重复 怎么办？去重。redis，groupBy

默认不支持递归遍历文件夹：自定义source，写递归代码，然后用tailDir读
复杂的问题一步一步的拆分，面试的时候就这样

几种channel，各种channel的优缺点。kafka channal，下一阶段必须是kafka
Kafka存磁盘。可靠性高，省去sink，效率高。
kafka有bug。额外的加上了topic前缀，传到flume，还需要额外的去掉

老师也是按照一条线来做的
从source，说到channal，说到sink。
sink，就想到什么问题。比如小文件问题
自拓展。

flume拦截器，不要有太复杂的逻辑，项目，简单的ETL+分类

企业开发，event类型，start类型。

让你介绍Flume，你要把你项目当中怎么用的给说】引进来，这就是经验。需要处理一下。混合

那问题又来了。一张表一个topic，做适当的聚合
如果自定义拦截器。
为了快，日志服务器不落盘。这么做，好处是什么，坏处是什么

把每个学科说多久，总结出来，给老师看看，怎么压缩。

基本就是上课讲的干货。自己能巴拉巴拉的说出来，但是太多了。

ganglia，要补充。put事务，个提

10分钟内全搞定？？？？？？？？？指的是说10分钟，还是？？？？10分钟说不完怎么办
明天问


tailDir，怎么搞，不是写在配置文件里面的吗？

老师就知道，kafka就有20件事，面试官问到kafka，立马全想起来这20件事，要的就是这种效果

老师说，分5块

kafka当机了怎么办？丢数了怎么办？重复了怎么办?消息积压了怎么办？怎么优化？分5大模块来记

基本模块：kafka的组成，生产者，消费者，zk，kafka搭建几台的公式，压测，先搭建，然后压测，然后再压测

如果不做压测，后果是什么（证明自己有开发经验的东西）：想知道1T数据，多长时间上传完，评估系统的速度
kakfa副本数，一般设置成2~3个就可以。副本解决了什么问题，引入了什么问题。来分析这件事。
数据保存多久，默认7天，生产环境下一般保存3天就可以。原因，日志服务器里面有保存。

为什么换公司，因为想在杭州发展
3天*副本数/70%

面试官问：做不做kafka的监控。做，用kafka Manager做监控，我们是自己开发的监控框架。
面试官说他们是自己写的kafka监控，怎么办？
	 你们公司技术很好，非常希望像你们学习。没事多夸夸面试官，跨技术强。秀他的技术，赶紧搭上。谁都愿意听好话。别表现得说面试官弱，也别盛气凌人，让面试官不喜欢你
		只要面试官秀自己，你就说，真厉害，都喜欢招自己喜欢的人
kakfa有多少topic：不知道，直接凉凉。不要直接说11张表。只要抛出了数字，哪12个？
  遇到问数字，遇到数数的问题：不要直接答数字，一边举例，一遍数，否则你先说了数字，到时候说不出来那么多，凉凉

  分区：3~10个

ISR，主要解决，leader宕机了，谁当老大的问题。
除了ISR之外，还有分区分配策略。range，轮询。默认采用range。range是怎么回事，说一下，用自己的话，说清是怎么回事。

仰视面试官，如果面试官秀自己的话。

kafka宕机了怎么办（所有宕机了，分别会产生什么问题）
从上游的flume开始分析，如果用的是file channal。短时间内，flume来解决，也没问题，日志服务器有
kafka丢数据了怎么办?
ack
问是配置1还是-1？看业务场景，如果是金融场景，用-1. 京东，丢个几百万条无所谓。一般追求效率，所以1就可以

不要直接说结果，一般分析着一边阐述，解决了背题的问题，因为你在思考。

kafka 数据重复了怎么办？
采用幂等性，或者后期去重
幂等性是怎么回事呢？说一下

Kafka数据积压了，怎么办？
提高自己，提高别人
提高自己：增加分区，10个分区，10个CPU。增大下游每批次拉去的条数。2000次左右就可以。
面试题只是关键词框架，光背下来是不够的

kafka的优化
高效读写数据，为什么快？

微批次处理，
配置，要总结成线索
kafka压缩，这样传输的数据就少了。

先提高自己，不行再加服务器

kafka优化：server 保存时间+副本数。

Hive
学任何框架，都有优化。面试都要主动去说优化

1，Hive架构
不要告诉老师，自己每天用自己的话总结一边。老师会告诉别人的。
就说自己记的笔记，然后记住大致的原理了，就用自己的话说

执行器内部怎么执行的
笔试题：Hive与MySQL与HBase的区别：数据量，查询速度
内部表和外部表的区别：建没建过外部表？建过，自己用的

orderby 用的很少。数据量太大，50T内存都不够用。

常用的函数有哪些？（这块要补充）
系统函数：系统时间函数，date_format，date_add，next_day，last_date
处理josn的，getJsonObject

自定义UDF，UDTF。有getJsonObject，为什么还要自定义UDF，UDTF。因为灵活
如果解析失败，如果是自定义UDTF，可以打印错误信息，如果是getJosnObject，只会报个错就完事了

自定义UDF，UDTF的步骤，这块要补充

process处理业务逻辑。开窗，排序。
开窗+排序：topN需求，一般要求现场手写，一定要会

（只要问到Hive，就会问到优化）hive优化：你做过哪些优化，体现实际工作经验，都是实在的证明材料


基本都涵盖了

Hive优化，需要补充
老师的顺序，mapJoin，行列过滤（问得多，先where过滤，后join），
数据量非常大，需要用分桶，但基本不用分桶。分区表用的比较多
合理设置map，reduce个数

小文件（merge，需要补充）：









